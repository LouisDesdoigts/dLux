{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afcdc02e-ddc9-4b6a-a82f-6537306cab8b",
   "metadata": {},
   "source": [
    "# A Better üêç PyTree üå≤ interface!\n",
    "\n",
    "So ‚ú® `Equinox` ‚ú® is an awesome package that gives us the ability to build object-oriented software in `Jax` ü§Ø, however it is a low-level package, designed around generality and flexibilty, which can make building a simple API for user-facing software a challenege. The less that astronomers have to learn about üò± `lambda` functions üò±, the better! To help with this, I've constructed a class with PyTree helper methods, designed to give a simpler and more intuitive interface.\n",
    "\n",
    "There is also a class designed to simplify interfacing with some of the most valueable packages used in conjunction with our software, namely `Optax` and `Numpyro` üòé.\n",
    "\n",
    "If you are new to `Jax`, note that all object are *immutable*, which simply means that you can NOT do in-place updates. ie any time we update some parameter, we return a new version of that object, this will become clear throughout the tutorial!\n",
    "\n",
    "\n",
    "---\n",
    "## What is a PyTree? \n",
    "\n",
    "PyTrees are the base object that Jax works with under the hood. Fundamentally they are any series of nested lists, tuples and dictionaries (https://jax.readthedocs.io/en/latest/pytrees.html). Equinox simply allows us to extend this definition to classes, hence object-oriented Jax! All classes in ‚àÇLux are PyTrees at the base level. Because of these arbitrary structures, indexing and setting new values 'leaves' can be difficult, since each 'leaf' must be referred to via some 'path'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c33047c9-7f3a-4488-96ba-2d1ca0e659ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Jax is running in 32-bit, to enable 64-bit visit: https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#double-64bit-precision\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dLux.base import Base, ExtendedBase\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065f39df-c804-4d73-87dc-aac860175b60",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "Lets create an example class that inherits from the `Base` class, which contains much of the low-level functionality. For this we will have some nested classes with various parameters. Lets instantiate these and have a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43609643-f579-4d2f-8419-089455127b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SuperGaussian(\n",
      "  variances=Variances(\n",
      "    var_x=10,\n",
      "    var_y=10,\n",
      "    some_list=[-1, -2],\n",
      "    some_dict={'a': 'foo', 'b': 'bar'}\n",
      "  ),\n",
      "  power=1\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Example class\n",
    "class Variances(Base):\n",
    "    var_x: float\n",
    "    var_y: float\n",
    "    some_list: list\n",
    "    some_dict: dict\n",
    "\n",
    "    def __init__(self, var_x, var_y, some_list, some_dict):\n",
    "        self.var_x = var_x\n",
    "        self.var_y = var_y\n",
    "        self.some_list = some_list\n",
    "        self.some_dict = some_dict\n",
    "\n",
    "# Example class\n",
    "class SuperGaussian(Base):\n",
    "    variances: object\n",
    "    power: float\n",
    "\n",
    "    def __init__(self, variances, power):\n",
    "        self.variances = variances\n",
    "        self.power = power\n",
    "        \n",
    "# Create an instance of the SuperGaussian object\n",
    "var_x, var_y = 10, 10\n",
    "power = 1\n",
    "some_list = [-1, -2]\n",
    "some_dict = {'a': 'foo', 'b': 'bar'}\n",
    "\n",
    "# Create the object\n",
    "variances = Variances(var_x, var_y, some_list, some_dict)\n",
    "pytree = SuperGaussian(variances, 1)\n",
    "\n",
    "# Examine the object\n",
    "print(pytree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a8371d-4e18-4b77-9b7e-9f797ebfc5c4",
   "metadata": {},
   "source": [
    "Nice! Here we have a nested structure, so to look at some of these class methods, we first need to understand the 'path' object.\n",
    "\n",
    "## The `path` object\n",
    "\n",
    "A `path` is simply a string that refers to some place in a pytree, with nested structures connected with dots '.', similar to accessing class attributes. Some example paths for our example pytree would look like this:\n",
    "\n",
    " - 'variances.var_x'\n",
    " - 'power'\n",
    " - 'variances.some_list.0'\n",
    " - 'variances.some_dict.a'\n",
    " - 'variances.some_dict'\n",
    "\n",
    "Each of these path objects refer to some place in the pytree, not neccesarily a leaf.\n",
    "\n",
    "---\n",
    "## New Methods\n",
    "\n",
    "We have built a series of method to operate on the parts of the pytree that these paths refer to, matching the jax.numpy.at[] method:\n",
    "\n",
    " - `.get()`\n",
    " - `.set()`\n",
    " - `.add()`\n",
    " - `.multiply()`\n",
    " - `.divide()`\n",
    " - `.power()`\n",
    " - `.min()`\n",
    " - `.max()`\n",
    " - `.apply()`\n",
    " - `.apply_args()`\n",
    "\n",
    "---\n",
    "\n",
    "### `.get()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "913af83b-c970-459c-933b-d6c8df31930a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "-1\n",
      "{'a': 'foo', 'b': 'bar'}\n"
     ]
    }
   ],
   "source": [
    "print(pytree.get('variances.var_x'))\n",
    "print(pytree.get('variances.some_list.0'))\n",
    "print(pytree.get('variances.some_dict'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4809d2f7-6278-48a7-bcd9-ad3a49df9120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc8ac532-e5b5-42fa-bc7c-9fb16a10642b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SuperGaussian' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Examine the output gaussian\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m gauss \u001b[38;5;241m=\u001b[39m \u001b[43mpytree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Plot\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(gauss)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SuperGaussian' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "# Examine the output gaussian\n",
    "gauss = pytree.model()\n",
    "\n",
    "# Plot\n",
    "plt.imshow(gauss)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531f842b-1239-4ba7-974f-9785a8154eb7",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Accessor Methods\n",
    "\n",
    "Accessors:\n",
    ">\n",
    "> - .get_leaf(path, path_dict=dict)\n",
    ">\n",
    "> - .get_leaves(paths, path_dict=dict)\n",
    "\n",
    "These two methods simply take in a single path or list of paths and return the corresponding attributes!\n",
    "\n",
    "Lets define some paths and check that everything works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe7e94c-fce7-4866-a89e-335bc52b558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "path1 = \"power\"\n",
    "path2 = \"variances.var_x\"\n",
    "path3 = \"variances.useless_list.1\"\n",
    "paths = [path1, path2, path3]\n",
    "\n",
    "# Access objects using .get_leaf()\n",
    "print(pytree.get(path1))\n",
    "print(pytree.get(path2))\n",
    "print(pytree.get(path3))\n",
    "\n",
    "# Access objects using .get_leaves()\n",
    "print(pytree.get(paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834c4912-9c1a-47f3-bed1-137f5e400b9b",
   "metadata": {},
   "source": [
    "Great! Simple enough, now lets move on the the Updater method\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "## Updater Methods\n",
    "\n",
    "> - .update_leaves(paths, values, path_dict=dict)\n",
    "\n",
    "This returns an updated version of the pytree, with the values places at the corresponding path.\n",
    "\n",
    "> - .apply_to_leaves(paths, fns, path_dict=dict)\n",
    "\n",
    "This returns an updated version of the pytree, with the values specified by the paths having the correspoinding function applied.\n",
    "\n",
    "\n",
    "Note that these methods performs no checks and do not preserve data type. If you pass in the wrong data-type you will very likely break your code. For example if you pass in a list instead of a jax array no errors will be thrown untill some other part of the downstream code expect a jax array in its place. Be careful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdbac4a-1fb2-4643-a5b3-f3d8650f4697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "path1 = \"power\"\n",
    "path2 = \"variances.var_x\"\n",
    "path3 = \"variances.useless_list.1\"\n",
    "paths = [path1, path2, path3]\n",
    "\n",
    "value = [-10]\n",
    "values = [1e2, 1e3, 1e4]\n",
    "\n",
    "print(pytree.set(path1, value))\n",
    "print(pytree.set(paths, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f52263a-32de-4405-b683-557b38b6ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "path1 = \"power\"\n",
    "path2 = \"variances.var_x\"\n",
    "path3 = \"variances.useless_list.1\"\n",
    "paths = [path1, path2, path3]\n",
    "\n",
    "fn = lambda x: 5 * x\n",
    "fns = [lambda x: -x, lambda x: 1e2 * x, lambda x: x + 5]\n",
    "\n",
    "print(pytree.apply(path1, fn))\n",
    "print(pytree.apply(paths, fns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3840d4d2-184a-4db0-a76f-d41f2d121d94",
   "metadata": {},
   "source": [
    "---\n",
    "### Nesting\n",
    "\n",
    "So now is a good time to introduce the nesting concept. Lets say we wanted to update multiple parameters with the *same* value. We can achieve this simply by nesting our paths within each other! Each value will be applied to the corresponding list of paths!\n",
    "\n",
    "This also works with the `.apply_to_leaves()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68117ead-71de-465c-b3e5-343aaeaa8031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "path1 = \"power\"\n",
    "path2 = \"variances.var_x\"\n",
    "path3 = \"variances.useless_list.1\"\n",
    "\n",
    "# Nested paths strucutre\n",
    "paths = [[path1, path2], path3]\n",
    "print(pytree.set(paths, [-1e2, 1e4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a61c988-8f5c-499f-99ae-cdf0de3102c5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Path dictionary\n",
    "\n",
    "The path dictionary as mentioned earlier is a way to further simplify our interface with PyTrees. By definintely the paths we care about inside the dictionary we can use simple keys to refer to those leaves! This is expecially useful for highly nested structures or leaves that we want to refer to many times. Note that we don't have to define *every* path the *every* leaf inside the dictionary, we can use a mix of paths and keys to refer to obejcts. We can also use the nesting concept with keys/paths interchangably.\n",
    "\n",
    "Note: The path_dict keys MUST NOT match any of the parameter names within any of the classes or sub-classes, or the methods will break. ie each key must be uniquely named from all parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8e7943-a8cc-401f-88ff-6a2ef2a2abaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmap = {\n",
    "    \"pow\":  \"power\",\n",
    "    \"xvar\": \"variances.var_x\",\n",
    "    \"yvar\": \"variances.var_y\",\n",
    "}\n",
    "\n",
    "print(pytree.get(\"pow\", pmap=pmap))\n",
    "print(pytree.get([\"pow\", \"xvar\"], pmap=pmap))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be21318e-6b49-4906-9d85-7c2ab2ebbf73",
   "metadata": {},
   "source": [
    "The methods have also been built to be flexible in the way that you pass in the path objects.\n",
    "\n",
    " 1. A single list of keys are understood referencing multiple leaves, rather than a single path\n",
    " 2. Nested lists of keys work identically to nested paths\n",
    " 3. Single keys do not *need* to be wrapped in lists\n",
    " \n",
    "Lets see those in action, using each of these edge cases to access the same parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd87974a-1fef-4c73-a9f2-fbd35750e48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "print(pytree.get([\"yvar\", \"pow\"], pmap=pmap))\n",
    "\n",
    "# 2\n",
    "print(pytree.get([[\"variances.var_y\"], \"power\"], pmap=pmap))\n",
    "\n",
    "# 3\n",
    "print(pytree.get([[\"variances.var_y\"], \"pow\"], pmap=pmap))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0966fd7b-0a5c-48e2-afee-486482f3a76f",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Interfacing Functions!\n",
    "\n",
    "\n",
    "### Equinox filter function interface!\n",
    "\n",
    "> .get_filter_spec(paths, path_dict=dict)\n",
    "\n",
    "This takes in a list of paths and returns a filter_spec ready to be passed straight into any Equinox filter function!\n",
    "\n",
    "Lets see how we can use this to optimise a model using Equniox along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b843c8-f8e4-4a6a-b2e7-71b8793fe334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dLux.base import ExtendedBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b199170a-ddef-4007-8944-32669897608b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Variances(ExtendedBase):\n",
    "    var_x: float\n",
    "    var_y: float\n",
    "    useless_list: list\n",
    "\n",
    "    def __init__(self, var_x, var_y, useless_list):\n",
    "        self.var_x = var_x\n",
    "        self.var_y = var_y\n",
    "        self.useless_list = useless_list\n",
    "\n",
    "\n",
    "class SuperGaussian(ExtendedBase):\n",
    "    variances: object\n",
    "    power: dict\n",
    "\n",
    "    def __init__(self, variances, power):\n",
    "        self.variances = variances\n",
    "        self.power = power\n",
    "\n",
    "    def model(self, flatten=False):\n",
    "        xs = np.linspace(-50, 50, 100)\n",
    "        XX, YY = np.meshgrid(xs, xs)\n",
    "\n",
    "        x = (XX / self.variances.var_x) ** 2\n",
    "        y = (YY / self.variances.var_y) ** 2\n",
    "\n",
    "        g = np.exp(-((x + y) ** self.power))\n",
    "\n",
    "        if flatten:\n",
    "            return g.flatten()\n",
    "        else:\n",
    "            return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8aa6a4-f7da-4061-b11e-a3da34158316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the SuperGaussian object\n",
    "var_x, var_y = 10, 10\n",
    "power = 1\n",
    "useless_list = [-1, -2]\n",
    "\n",
    "# Create the object\n",
    "variances = Variances(var_x, var_y, useless_list)\n",
    "pytree = SuperGaussian(variances, 1)\n",
    "\n",
    "# Examine the object\n",
    "print(pytree)\n",
    "\n",
    "# Examine the output gaussian\n",
    "gauss = pytree.model()\n",
    "\n",
    "# Plot\n",
    "plt.imshow(gauss)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ca4b65-cf86-489f-a502-5eb55dd919d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfc6533-fb58-443c-b4e1-0f0c8f26021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to the variables we care about, and new values\n",
    "paths = [\"xvar\", \"yvar\", \"pow\"]\n",
    "new_values = [np.array(15.0), np.array(5.0), np.array(1.5)]\n",
    "\n",
    "# Get a new pytree to optimise\n",
    "model_pytree = pytree.set(paths, new_values, pmap=pmap)\n",
    "\n",
    "# Generate a filter_spec to pass to equinox filter functions\n",
    "filter_spec = model_pytree.get_args(paths, pmap=pmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5172a49c-510d-47df-bead-2385e675f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "@eqx.filter_jit()\n",
    "@eqx.filter_value_and_grad(arg=filter_spec)\n",
    "def loss_fn(model, data):\n",
    "    return np.sum((model.model() - data) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5333f023-bfcd-4049-9d49-1ae824a05cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some fake data and evaluate loss\n",
    "fake_data = pytree.model()\n",
    "loss, grads = loss_fn(model_pytree, fake_data)\n",
    "print(loss, grads.variances.var_x, grads.variances.var_y, grads.power)\n",
    "print(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f277f26-8897-4e3b-8a0b-ab077f67e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a basic step function\n",
    "get_step = lambda grads, lr: jax.tree_map(lambda leaf: -lr * leaf, grads)\n",
    "\n",
    "# Optimise the model\n",
    "for i in tqdm(range(500)):\n",
    "    loss, grads = loss_fn(model_pytree, fake_data)\n",
    "    model_pytree = eqx.apply_updates(model_pytree, get_step(grads, 1e-2))\n",
    "\n",
    "# Print the final values to check that eveything works\n",
    "(model_pytree.variances.var_x, model_pytree.variances.var_y, model_pytree.power)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228eb159-95f9-46d5-bf8a-bbf39285b679",
   "metadata": {},
   "source": [
    "Awesome! As we can see we were able to recover out true parameters!\n",
    "\n",
    "---\n",
    "\n",
    "### Optax param_spec interface!\n",
    "\n",
    "So next we want to be able to actually optmise a model using optax, so we need to define a param_spec!\n",
    "\n",
    "> .get_param_spec(path, groups, path_dict=dict, get_filter_spec=bool)\n",
    "\n",
    "This function lets us generate a param_spec in order to group parameters and apply optimiser to them. We could pass in the filter_spec from before, or we could use the inbuilt functionality that returns the correct filter_spec for the given param_spec.\n",
    "\n",
    "Lets group the two variances together, and the power to its own group, and see how we go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d36b1b-4ae8-4684-b13c-aae3f6040e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec6b5d4-d340-4073-9d5c-17864e6632e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [None]\n",
    "values == [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad642b58-c508-4cf4-92c1-56c2a540c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to the variables we care about, and new values\n",
    "paths = [\"xvar\", \"yvar\", \"pow\"]\n",
    "new_values = [np.array(15.0), np.array(5.0), np.array(1.5)]\n",
    "\n",
    "# Get a new pytree to update\n",
    "model_pytree = pytree.set(paths, new_values, pmap=pmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eda9e70-5777-40cb-9b0c-dca9a5000459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter groups for the param spec\n",
    "# Use the nested path functionality to group the variances together!\n",
    "paths = [[\"xvar\", \"yvar\"], \"pow\"]\n",
    "groups = [\"var\", \"pow\"]\n",
    "param_spec, filter_spec = model_pytree.get_param_spec(\n",
    "    paths, groups, get_args=True, pmap=pmap\n",
    ")\n",
    "\n",
    "print(param_spec)\n",
    "print(filter_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7602c6c8-a489-43bf-8765-01474c1f610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define Learning rates\n",
    "var_lr = 1e0\n",
    "pow_lr = 1e-1\n",
    "\n",
    "# Use the generated param spec to map optimisers\n",
    "# Be sure to match the values defined in 'groups'!\n",
    "optim = optax.multi_transform(\n",
    "    {\"null\": optax.adam(0.0), \"var\": optax.adam(var_lr), \"pow\": optax.adam(pow_lr)},\n",
    "    param_spec,\n",
    ")\n",
    "\n",
    "# Initialise & optimise a for single epoch\n",
    "opt_state = optim.init(model_pytree)\n",
    "for i in tqdm(range(100)):\n",
    "    loss, grads = loss_fn(model_pytree, fake_data)\n",
    "    updates, opt_state = optim.update(grads, opt_state)\n",
    "    model_pytree = eqx.apply_updates(model_pytree, updates)\n",
    "\n",
    "# Print the final values to check that eveything works\n",
    "(model_pytree.variances.var_x, model_pytree.variances.var_y, model_pytree.power)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12adbc63-3739-443d-a78d-f3dc887fd210",
   "metadata": {},
   "source": [
    "Great it all works!\n",
    "\n",
    "---\n",
    "\n",
    "### Optax optimiser interface!\n",
    "\n",
    "> .get_pytree_optimiser(paths, optimisers, get_filter_spec=bool)\n",
    "\n",
    "So in most use-cases, we can avoid the need to interact with the optax.multi_transform function all together, allowing us to *only* define the optimisers we wish to apply to each parameter and group. Lets have a look how we can do that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029862a6-c1d1-4c38-89f9-6e514e53f44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to the variables we care about, and new values\n",
    "paths = [\"xvar\", \"yvar\", \"pow\"]\n",
    "new_values = [np.array(15.0), np.array(5.0), np.array(1.5)]\n",
    "\n",
    "# Get a new pytree to update\n",
    "model_pytree = pytree.set(paths, new_values, pmap=pmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1da0b9-f7d2-4687-8873-96d40be0bf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and corresponsing optimisers\n",
    "paths = [[\"xvar\", \"yvar\"], \"pow\"]\n",
    "optimisers = [optax.adam(1e-1), optax.adam(1e-2)]\n",
    "\n",
    "# Get optimiser and filter_spec\n",
    "optim, fs = pytree.get_optimiser(\n",
    "    paths, optimisers, get_args=True, pmap=pmap\n",
    ")\n",
    "\n",
    "# Initialise & Optimise\n",
    "opt_state = optim.init(model_pytree)\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    loss, grads = loss_fn(model_pytree, fake_data)\n",
    "    updates, opt_state = optim.update(grads, opt_state)\n",
    "    model_pytree = eqx.apply_updates(model_pytree, updates)\n",
    "\n",
    "# Print the final values to check that eveything works\n",
    "(model_pytree.variances.var_x, model_pytree.variances.var_y, model_pytree.power)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0d2b04-b1fb-4ac8-b004-77d94e67ee53",
   "metadata": {},
   "source": [
    "How easy was that!\n",
    "\n",
    "---\n",
    "\n",
    "### Numpyro interface!\n",
    "\n",
    "The last package we want to be able to interact with easily is Numpyro, so we can run MCMCs!\n",
    "\n",
    "> .update_and_model(model_fn, paths, values, path_dict=dict, *args, **kwargs)\n",
    "\n",
    "So for this method the paths, values and path_dict should all be familiar by now. The difference here is that we also must specify with function is the one used th generate our model. This is done using a string to reference the method. Similarly if we need to pass extra agruments into the modelling function we can do that with the *args and **kwargs. I will show to to pass in key word arguments here!\n",
    "\n",
    "For those who haven't used Numpyro, you need to define a modelling function with all of the parameters you wish to sample. This minimal example should give you a good idea of what to do, but for a more in-depth exploration of its functionality and behaviour, check out [this great tutorial](https://dfm.io/posts/intro-to-numpyro/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72999f1c-d7da-4ad6-9f98-5d58eb5d8dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro as npy\n",
    "import numpyro.distributions as dist\n",
    "import jax.random as jr\n",
    "import chainconsumer as cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bcaf8a-608f-4e90-ae9f-998f74910131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelling_fn(data, model, path_dict=None):\n",
    "    \"\"\" \"\"\"\n",
    "    # Define parameter sampling\n",
    "    var_x = npy.sample(\"x variance\", dist.Uniform(0, 100))\n",
    "    var_y = npy.sample(\"y variance\", dist.Uniform(0, 100))\n",
    "    power = npy.sample(\"power\", dist.Uniform(0, 10))\n",
    "\n",
    "    # Define paths and values\n",
    "    paths = [\"xvar\", \"yvar\", \"pow\"]\n",
    "    values = [var_x, var_y, power]\n",
    "\n",
    "    with npy.plate(\"data\", len(data)):\n",
    "        poisson_model = dist.Normal(\n",
    "            model.update_and_model(\n",
    "                \"model\", paths, values, pmap=pmap, flatten=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return npy.sample(\"super-gaussian\", poisson_model, obs=data)\n",
    "\n",
    "\n",
    "# This has not yet been correctly configured for the mkdocs framework, but will \n",
    "# be at some time in the future\n",
    "# graph = npy.render_model(\n",
    "#     modelling_fn, model_args=(fake_data.flatten(), model_pytree, path_dict)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c040639-8e7e-411b-ac41-1939b32f1bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the model above, we can now sample from the posterior distribution\n",
    "# using the No U-Turn Sampler (NUTS).\n",
    "sampler = npy.infer.MCMC(\n",
    "    npy.infer.NUTS(modelling_fn),\n",
    "    num_warmup=2000,\n",
    "    num_samples=2000,\n",
    "    progress_bar=True,\n",
    ")\n",
    "%time sampler.run(jr.PRNGKey(0), fake_data.flatten(), model_pytree, pmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736225f2-52b5-4966-b177-22889f3ac1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.print_summary()\n",
    "values_out = sampler.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a343d9cd-0d1d-455a-956e-dbc7cec0edc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = cc.ChainConsumer()\n",
    "chain.add_chain(values_out)\n",
    "chain.configure(\n",
    "    serif=True, shade=True, bar_shade=True, shade_alpha=0.2, spacing=1.0, max_ticks=3\n",
    ")\n",
    "fig = chain.plotter.plot(truth={\"power\": 1, \"x variance\": 10, \"y variance\": 10})\n",
    "fig.set_size_inches((15, 15));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b602408-0b48-462a-a027-143a5782763a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e00adb4-4d96-48db-9a63-619cd4e58658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
